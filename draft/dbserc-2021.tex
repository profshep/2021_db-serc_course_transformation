\documentclass[10pt,letterpaper]{article}

\input{preamble}

\begin{document}
\head{Proposal overview and objectives} %<<overview>>

Student-centered pedagogies have been developed and demonstrated to improve student learning. 
For example, in the Process Oriented Guided Inquiry Learning (\pogil) approach, students construct their own knowledge
through a learning cycle of exploration, concept invention, and application.
Students progress through carefully constructed worksheets in small groups to explore a `model' (an information rich data display), answer questions that make them think about the model, propose explanations for what they have explored, and then apply those concepts to further problems.
% 
As successful as I have found \pogil to be, the assessment strategies I have used are still teacher-centered. Typical programs of high stakes assessments fundamentally undermine my learning goals for students. Rather than focusing on growing as a learner and improving as a scholar, traditional grading incentivizes a grade focus in which students try to maximize the points they can get from any assignment for the minimum of effort, independent of their learning. Poor performance on an assessment is met with the attitude that it is too late to do anything about it, so move on to the next chapter. As I result, I hate grading not because it requires effort, but because students pay no attention to the feedback and do not use the feedback as a learning opportunity. 
%work on this
The traditional grading approaches that I have used are a problem because they lead to student frustration, stereotype threat, and attrition from STEM. 

A long range goal of my teaching is to help students embrace a life of growth and learning both in the subject matter of Chemistry and in the metacognitive and metaemotional skills they need to succeed beyond the Chemistry classroom.
%
The overall objective for this proposal is to develop a proficiency-based assessment structure for General Chemistry 1 that will be transferrable to other instructors in the General Chemistry program. 
% <<hypothesis>> 
The \textit{central hypothesis} is that a proficiency-based grading structure will better encourage and motivate students to identify their weaknesses and work to improve. 
% what would be better?
\fixme{better \begin{enumerate*}[label=\alph*).] \item engagement \item learning outcomes \item attitudes to the subject \item self-efficacy \end{enumerate*}} 
%
This hypothesis is based on the demonstrated effectiveness of specifications grading and standards-based grading in other General Chemistry courses.\cite{Boesdorfer2018,Martin2019}
%<<rationale>>
The \textit{rationale} of this project is that the combination of student-centered pedagogy  and student-centered assessment will synergistically improve learning outcomes for students.  These course materials will be developed with a team of General Chemistry faculty to maximize the transferability of the materials. 
%<<qualifications>>
Our team is uniquely qualified to successfully execute this project because of our experience implementing \pogil in the large-enrollment General Chemistry classroom.

The specific goals for this project are to:
\begin{enumerate}[nosep,label=\textbf{\arabic*}.]
%\begin{itemize}[nosep]
\item \aimtext{aim:grading}{Develop student learning objectives based and align a proficiency-based grading scheme to those objectives.} 
We will design a set of learning objectives  based on Marzano's taxonomy, which provides a structure to specify appropriate learning objectives at multiple levels of conceptual difficulty. The four tiers of achievement -- \textit{Recall}, \textit{Comprehension}, \textit{Analysis}, and \textit{Use} -- will be articulated for each learning objective. With this set of learning objectives, we will craft a grading scheme based on a standards-based grading that incorporates both many modes of frequent, low-stakes student work -- online adaptive learning systems (Sapling Learning Curve), online homework (Sapling Learning), individual and group quizzes, discussion boards, \fixme{other? too much?}.

\item \aimtext{aim:implement}{Design assessments that align to the learning objectives and implement the grading scheme.}
For each learning objective and each level of mastery, assignments will be refactored to best align with the stated learning goals. While many materials exist in the form of question banks, rarely are these questions explicitly aligned with learning objectives. This aim will curate materials like quiz questions and build quizes for each learning unit and design multiple attempts into the assessment delivery system. In addition,  a framework to articulate to students what learning objectives they have mastered and what areas need development will be implemented in the Canvas LMS.

\item \aimtext{aim:assess}{Assess and disseminate the course transformation.}
This aim will measure the impact of the transformation on student learning and attitudes. Based on our previous attitudinal data, we will compare the effect of the course on student self-efficacy and engagement, especially measures of student frustration. In addition, we will measure differential impact on students based on demographic factors such as gender. Women tend to underperform men on high-stakes assessments even though they outperform them at low-stakes assessments. We will measure student performance in the transformed course to see if it alleviates this gender bias.
\end{enumerate}
\myaimref*{aim:grading} will develop a clear, comprehensive set of learning objectives and an associated grading scheme. 
\myaimref*{aim:implement} will develop the actual assessment instruments that will assess student learning and communicate to students their progress. Finally, \myaimref*{aim:assess} will measure how effectively the course transformation has achieved each of its goals and share these results with other faculty.

This project is a \textit{creative} and \textit{original} approach to \fixme{etc etc etc}
%
\oldtext{The \textit{expected outcomes} of this project will be course materials whose effectiveness has been tested. 
%
The development of this project is important at several levels. First, in my classroom, these materials will help my students learn some of the hardest material better. Second, these materials can be distributed to other sections of the same course within the Department of Chemistry. Third, it will serve as a nucleus for further incorporation of active engagement aided by technology in the broader natural sciences community at Pitt. Last, validated materials can be disseminated in the \pogil community and adopted at universities around the country. }
%
Finally, this work engages a question very timely question in the broader scholarship of teaching and learning -- how do we best build student-centered assessments that match student-centered pedagogies? 
\fixme{expand -- maybe something like how to implement multiple attempts in large-enrollment courses without overwhelming grader resources}

\oldtext{
\head{Expected significance}
This project addresses a central goal of the dB-SERC -- individualizes instruction through interactivity, and personalizes learning through guided inquiry. 
%
%
Finally, the approach embodied in this proposal, once it has been validated, may be generalized to transforming large lecture courses in chemistry and physics.

%

\head{Background and preliminary results}

Guided inquiry methods~\cite{farrellJCE-99,lewisJCE-05,minderhoutBMBE-07,moog-08,eberleinBMBE-08}, Process Oriented Guided Inquiry Learning~\cite{moog-08} (\pogil) for example, effectively bring active learning into the science classroom. For example, in my thermodynamics and statistical mechanics courses, students first explore a model, then construct the explanation, and then learn the standard terminology for that concept. Guided inquiry methods improve student learning outcomes and attitudes in both introductory and advanced chemistry classrooms~\cite{lewisJCE-05}. 

\subhead{The problem}

Typical guided inquiry materials are worksheets which are \textit{static}, but physical chemistry is \textit{dynamic}. 
Static pictures are poor representations on which to develop an understanding of how molecules move: how molecular collisions create drag but also diffusion; how the kinetic energy of one particle is randomized through collisions to become heat;
how the flow of heat or particles is related to a gradient of temperature or concentration. All of these points are inherently \textit{dynamic}, which is a deep connection to the other objectives of this proposal. Students must employ complex spatiotemporal reasoning (how do things move as a function of time), to connect molecular pictures to macroscopic observables to symbolic representations of those parameters~\cite{burkeJCE-98,marsonJCE-11}. 

\subhead{The innovation}

I have developed electronic course materials (\textsc{html5} applications) for my undergraduate Physical Chemistry courses ($\sim$35 students). The \textsc{html5} applications run on any computer with a modern browser, (Windows, Linux, or Mac), including desktops, laptops, tablets, smartphones, and other app-capable devices. Programs are written in JavaScript, which is slower than C-code by only a factor of 3 for most numerical computation benchmarks~\cite{Khan2014}, which makes it acceptable for scientific computations of this scale. Emscripten and typed arrays offer modest speed-ups~\cite{Khan2014}. 

These computer simulations are \textbf{integrated into guided inquiry materials} and have the potential to radically change the way students engage with the toughest concepts in physical chemistry. Paper worksheets are the proven medium for students to develop their thoughts, compose their sentences, and conduct their calculations. Integrating the computer simulations with the paper record is as straightforward as a Quick Response (QR) code~\myfigref[a]{fig:mockups}. All mobile devices have QR code readers available for free. Simply scanning the QR code takes the browser directly to the webpage of the model. A human readable format is also provided.

Students can interact with the dynamic models~\myfigref[b]{fig:mockups} in real time. As the molecular representation evolves (upper portion of the screen), students can `poke' the simulation and observe how the macroscopic information (bottom of the screen) responds. Three examples \myfigref[b]{fig:mockups} embody concepts that most students find very hard to master, Brownian motion, heat transport, and the structure of liquids.

Sufficient numbers of students have access to smart-phones, tablets, and laptops in class that every \pogil group had access to at least one this past spring semester. The ability to use students' devices in the classroom for learning purposes exists today and will only grow. 

Moving between visualization and class discussion is seamless. Preliminary development of the applications has demonstrated dynamics of $\sim500$ hard spheres in two-dimensions on all platforms in portable code (JavaScript). User interactions include touch, swipe, and multitouch (pinch). These preliminary results show both the technical feasibility of the approach and the viable real-world classroom implementation. The next  tasks are to assess the impact of my implementation of \pogil \myaimref{aim:pogil}, to assess the impact of these new models on student learning and attitudes \myaimref{aim:dynamics}, and to refine the implementation of the models based on the results of the assessments \myaimref{aim:refine}.

\subhead{Assessment strategy}

The efficacy of my implementation of the  \pogil approach will be assessed with multiple methods. Though this is mostly `action research', there is the possibility to share results in papers at \pogil conferences. Therefore,  I will seek IRB approval. 

The general strategy is to use the parallel section of Physical Chemistry 2 as a control population to assess the differences between the \pogil approach and a traditional lecture on student learning and attitudes. Provided that the instructor (TBD) approves, this could be a powerful method of testing differences between pedagogical styles. As much as possible, the relevant assessment tools will be deployed in both classes. 

Nevertheless, there are two important variables to control: population bias and instructor bias. First, \textit{population bias} could affect the quantitative assessments of learning. While student numbers in each section are in the 20--40 range, one section is a morning class and one section is an evening class. To control for the possible bias this could induce, I will use the student QPA which should be a relevant proxy for student ability. The Director of Undergraduate Studies (Bandik) will provide anonymized QPA for each section, which can be used in equivalence testing to test if the sections are similarly populated. Second, \textit{instructor bias} could affect the differences in student attitudes. Many surveys of teaching are influenced by the ``beauty contest'' effect. How much students ``like'' a certain professor can influence the answers they give. Student Assessments of Learning Gains (SALG) instruments are a demonstrated method to elicit specific and actionable feedback from students which separates, as much as possible, the teacher from the teacher's pedagogy~\cite{Seymour2000}. The SALG survey will be a comprehensive assessment of the learning gains in the class, the \pogil method, as well as individual activities (Appendix), and will be one important assessment instrument because it is known to be resistant to instructor bias.
}%end oldtext

%
% AIM Develop grading scheme and learning objectives
%
\aim{aim:grading}
Though the object of teaching is for students to learn,  the assessments used and the grading scheme applied grading often align with those learning objectives in only an intuitive, unexpressed, or traditional way. Clear-headed assessment of student learning should begin with a clear articulation of the learning objectives that is integrated into all aspects of student work and communication with students. This wholistic approach will help students identify the areas that they have mastered and the areas in which  they need to improve.

\subaim{Student Learning Objectives}


\subaim{Grading scheme}
\oldtext{
\subsubaim{Pre/post assessment} The effect of a \pogil pedagogy in general on class attitudes will be measured by the ASCI (V2)~\cite{Xu2011} instrument at the beginning and at the end of the course. The ASCI (V2) survey is brief (8 question) so it can unobtrusively be used both at the beginning and the end of the course. The ASCI (V2) survey will assesses students attitudes to the discipline of Physical Chemistry in two regards, both to its \textit{intellectual accessibility} and to its \textit{emotional satisfaction}. The working hypothesis is that the active learning environment of the \pogil classroom will lead to shifts in both categories compared with the comparison group. The purpose is to identify the changes in student attitude that the active classroom engenders.
%First, the Chemistry Self-Concept Inventory (CSCI) assessment tool~\cite{Bauer2005} will be administered pre/post course. This tool assesses the relationships between  math, chemistry, and visualization. My working hypothesis is that attitudes towards both mathematical and visualization scores will become more positive.

\subsubaim{Student self-assessment} The end of semester SALG survey will also include questions focussing on changes in attitude, specifically
\begin{enumerate*}[label=\textbf{\arabic*.)}]
  \item class impact on attitudes,
\item the class structure overall, and
\item the class activities
\end{enumerate*}

\subsubaim{Focus groups} In addition to these quantitative surveys, qualitative data will be obtained in focus group sessions. The sessions will be modelled on those of Dr. David Nero (Pitt Physics), to elicit feedback on the effectiveness of the \pogil approach to the course. Sessions will be voluntary and occur at three points in the semester. Parallel focus sessions will be run in the other Physical Chemistry 2 section, coordinated with the instructor. 

Reported differences in student enjoyment and attitude towards the discipline of Physical Chemistry would confirm my hypothesis that the \pogil approach in general improves student attitudes towards learning in this discipline. 
}%end oldtext

%
% AIM Implementation
%
\aim{aim:implement}
\oldtext{
My working hypothesis is that student learning of dynamics concepts will improve based on these simulation interventions. I will test the hypothesis through both quantitative and qualitative approaches. 
}

\subaim{Assessment of attitudes}
\oldtext{
\subsubaim{Evaluation} Specific feedback will be requested immediately after each dynamic intervention on a Likert-like scale. A brief survey will request evaluation of
\begin{enumerate*}[label=\textbf{\arabic*.)}]
  \item the ease of use, 
\item the perceived utility, 
\item the effectiveness in aiding learning, 
\item the interest level, and  
\item a free response asking for suggestions for improvements to aid student learning.
\end{enumerate*}

\subsubaim{Focus group} Specific prompts of the focus groups in the target Physical Chemistry 2 classroom will target the effectiveness of these in-class activities in supporting student learning of these concepts. Questions will aim to elicit the effectiveness, the ease of use, the approachability, and the interest level of the dynamic simulations in a more free-response setting. This more detailed feedback should aid in the interpretation of the quantitative data collected.
}%old text

%\subaim{Expected outcomes}

%\subaim{Potential problems and alternative approaches}

%
% AIM Assess and disseminate
%
\aim{aim:assess}
\oldtext{some kind of introduction}

\subaim{Assess Student Learning}

\subsubaim{Course content} Compare to 2018-2021 data for assessment items.

\subsubaim{ACS exam} ACS Gen Chem 1 Paired Question exam. \fixme{[add to budget]} Compare to 2018, 2019 ACS exam data. Scores for POGIL sections.

\subsubaim{Follow on performance} Track students going into Gen Chem 2 with other instructors. 

%http://chemexams.chem.iastate.edu/instructors/assessment-materials/exams
\subsubaim{Student learning self-assessment}
Student perception of learning gains will be assessed through an instrument developed through \url{salgsite.org}, which provides easy implementation and analysis of the questionnaires. 

The question areas relevant to course learning will include
\begin{enumerate*}[label=\textbf{\arabic*.)}]
  \item how do in-class activities support learning,
\item how do assessment structure support learning.
\end{enumerate*}

\subsubaim{Demographic effects} We will compare student performance sorted by demographic category and compare against prior years. Gender performance gaps have been identified in STEM classrooms at Pitt and suggested to be present in our Chemistry program. We will identify the magnitude of the gender performance gap in our previous General Chemistry classes 2018--2021 and compare this with student performance after the course transformation.

\subaim{Assess Student Attitudes}
We will reimplement the surveys of student opinions used in the 2018-2019 terms that captured student.
We will also capture data from concurrent \pogil and traditional lecture courses. Instructors will be encouraged to offer students extra credit or some reward for participation.

\subsubaim{Engagement} 

\subsubaim{Self-efficacy}
The attitude surveys will include questions to assess student perceptions of their self-efficacy in postively coded questions like, ``When I face a hard problem, I feel like I can solve it,'' and negatively coded questions like, ``I get frustrated easily when I face a challenging problem.'' These showed a meaningful shift after the implementation of \pogil  in the large-enrollment course compared to traditional lecture.

\subsubaim{Identity}
``I am a science kind of person.'' ``I am a biology kind of person.'' ``I am a chemistry kind of person.'' ``I am a physics kind of person.'' \fixme{TODO: review previous results from Paulette.}

\subsubaim{Anxiety}
``Taking the assessments (quizzes and exams) was stressful.'' ``I felt relaxed completing assessments (quizzes and exams).'' ``I am worried about my performance on my next assessment (quiz or exam).'' ``I feel confident about my next assessment (quiz or exam).''

\subaim{Disseminate to Other Chemistry Faculty}
\oldtext{

Currently three activities have been developed and deployed \myfigref{fig:mockups}. The student reaction was positive. Nevertheless, the activities clustered at the end of the semester. Based on this initial success, the activities will be expanded both to support more of the learning goals of the class, as well as to spread the simulations more evenly through the semester. New simulations will include 
\begin{enumerate*}[label=\textbf{\arabic*)}]
\item the dynamical approach to equilibrium (in the first week of class);
\item the flow of heat in systems described by a discrete energy-level diagram (before the first midterm exam); and
\item the thermodynamic cycle of an engine (before the second midterm).
\end{enumerate*}
These three new simulations will meet the needs revealed by student misconceptions in this past semester.


\head{Expected outcomes}

The three aims will together provide a route to demonstrably effective course materials. \myaimref*{aim:pogil} provides the effectiveness of the \pogil approach for this particular course. In that context, \myaimref*{aim:dynamics} provides a comprehensive assessment of the strengths and weaknesses of the dynamic course materials I have developed. \myaimref*{aim:refine} provides a pathway to incorporate the gained understanding into improved materials.

\subhead{Potential problems and alternative approaches}

Though unlikely, it is possible that the instructor of the parallel section of Physical Chemistry 2 will not agree to cooperate. This problem could eliminate the control population. Nevertheless, the diverse portfolio of student feedback I plan to collect is not exclusively dependent on the ability to make the case and control comparison for quiz and exam questions. A meaningful data-set should still be possible given the student self-assessment of learning gains and student feedback on the effectiveness of the dynamic displays to aid their learning.

Another potential problem, is that the student populations in the two courses may indeed be different. Recent experience in the course suggests that both courses have roughly the same proportions of A's and B's, nevertheless, the equivalence tests may fail in this year. Having unequal populations means one cannot say this study \text{proves} that \pogil is better in an absolute sense, but that is not the goal of this project. The differences in learning gains and attitude shifts should still be perceptible, and the development and refinement of course materials will still be valuable.

\head{Timeline and Budget justification}

The funds from this award will go to dedicated time during summer 2015 to prepare the new simulations and the assessment tools (surveys, questionnaires, rubrics for marking free-response questions, and focus group preparation) (0.5 month summer salary). The project will support two graduate students (1 month effort each). I will mentor the graduate students in evidence-based teaching and assessment methods. The students will then get hands-on experience designing and evaluating the pre- and post-assessments for these interventions and participating in a focus group session (Spring of 2016). An undergraduate programmer will revise and enhance the simulations in Fall 2015 (\$10 / hour, 10 hours / week, 15 weeks).
}%end oldtext
\newpage
\raggedright\footnotesize\singlespacing
\renewcommand{\refname}{\large\textbf{References}}
%\renewcommand{\refname}{\Large\textsc{\textbf{\lsstyle \MakeTextLowercase References}}}
\bibliography{library_fixed,library_extra}
%trick to not typeset the bibliogrpahy but make all the data
%{\setbox0\vbox{\bibliography{library,sgr,teaching}}}

% \newpage
% \includepdf[pages={1-},offset=75 -75]{dB-SERC_BUDGET.pdf}

% \newpage
% \includepdf[pages={1-},offset=75 -75]{dBSERC_support_letter_Garrett-Roe_2015.pdf}


\end{document}